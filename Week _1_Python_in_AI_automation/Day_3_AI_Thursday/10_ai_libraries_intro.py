"""
DAY 3 - LESSON 10: Introduction to AI and Data Science Libraries
=============================================================

Learning Objectives:
- Understand NumPy and arrays
- Learn Pandas for data analysis
- Understand scikit-learn basics
- Learn about machine learning workflow
- Understand AI/ML roadmap and next steps

Key Concepts:
- NumPy: Numerical computing with arrays
- Pandas: Data analysis with DataFrames
- scikit-learn: Machine learning algorithms
- Features and Labels: Input and output for ML models
- Training and Testing: How to evaluate models
"""

# Note: This lesson assumes libraries are installed via requirements.txt
# Install with: pip install -r requirements.txt

print("=== INTRODUCTION TO AI AND DATA SCIENCE LIBRARIES ===\n")


# ===== SECTION 1: Understanding NumPy =====
print("=== NUMPY BASICS ===\n")

print("""
NumPy: Numerical Python
- Fast numerical computing
- Works with arrays and matrices
- Foundation for most data science libraries

Key concepts:
- Array: Collection of elements (like list but more efficient)
- ndarray: N-dimensional array
- Element-wise operations: Operations on all elements at once
""")

try:
    import numpy as np
    
    # Create arrays
    arr = np.array([1, 2, 3, 4, 5])
    print(f"Array: {arr}")
    print(f"Shape: {arr.shape}")
    print(f"Data type: {arr.dtype}")
    
    # Array operations
    print(f"\nOperations:")
    print(f"  Sum: {np.sum(arr)}")
    print(f"  Mean: {np.mean(arr)}")
    print(f"  Max: {np.max(arr)}")
    print(f"  Min: {np.min(arr)}")
    
    # 2D array (matrix)
    matrix = np.array([[1, 2, 3], [4, 5, 6]])
    print(f"\nMatrix shape: {matrix.shape}")
    print(f"Matrix:\n{matrix}")
    
except ImportError:
    print("NumPy not installed. Install with: pip install numpy")


# ===== SECTION 2: Understanding Pandas =====
print("\n\n=== PANDAS BASICS ===\n")

print("""
Pandas: Data Analysis Library
- DataFrames: 2D labeled data (like spreadsheet)
- Series: 1D labeled data
- Easy data manipulation and analysis
- Great for working with CSV, JSON, Excel files
""")

try:
    import pandas as pd
    
    # Create DataFrame from dictionary
    data = {
        'Name': ['Ahmed', 'Sara', 'Ali', 'Fatima'],
        'Age': [25, 23, 24, 22],
        'Score': [95, 88, 92, 90],
        'City': ['Cairo', 'Alexandria', 'Giza', 'Aswan']
    }
    
    df = pd.DataFrame(data)
    print("DataFrame:")
    print(df)
    
    print(f"\nDataFrame info:")
    print(f"  Shape: {df.shape}")
    print(f"  Columns: {list(df.columns)}")
    
    # Basic statistics
    print(f"\nStatistics:")
    print(f"  Average age: {df['Age'].mean()}")
    print(f"  Average score: {df['Score'].mean()}")
    print(f"  Highest score: {df['Score'].max()}")
    
    # Filtering
    print(f"\nFiltering (Score >= 90):")
    high_scorers = df[df['Score'] >= 90]
    print(high_scorers)
    
except ImportError:
    print("Pandas not installed. Install with: pip install pandas")


# ===== SECTION 3: Understanding scikit-learn =====
print("\n\n=== SCIKIT-LEARN BASICS ===\n")

print("""
scikit-learn: Machine Learning Library
- Simple and efficient tools for ML
- Supervised learning: Classification, Regression
- Unsupervised learning: Clustering, Dimensionality reduction
- Tools for model selection and evaluation
""")

try:
    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score
    
    print("âœ“ scikit-learn is available")
    
    # Load sample dataset
    iris = load_iris()
    X = iris.data  # Features
    y = iris.target  # Labels
    
    print(f"\nIris Dataset:")
    print(f"  Features shape: {X.shape}")
    print(f"  Samples: {X.shape[0]}")
    print(f"  Features per sample: {X.shape[1]}")
    print(f"  Classes: {len(set(y))}")
    
    # Split data into training and testing
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )
    
    print(f"\nTrain-test split:")
    print(f"  Training samples: {len(X_train)}")
    print(f"  Testing samples: {len(X_test)}")
    
    # Train model
    print(f"\nTraining RandomForest classifier...")
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)
    print("  âœ“ Model trained")
    
    # Make predictions
    predictions = model.predict(X_test)
    
    # Evaluate
    accuracy = accuracy_score(y_test, predictions)
    print(f"\nModel accuracy: {accuracy:.2%}")
    
except ImportError as e:
    print(f"scikit-learn or dependencies not available: {e}")
    print("Install with: pip install scikit-learn numpy scipy")


# ===== SECTION 4: Machine Learning Workflow =====
print("\n\n=== MACHINE LEARNING WORKFLOW ===\n")

print("""
Typical ML workflow:

1. DATA COLLECTION
   â””â”€ Gather data from various sources
   
2. DATA PREPARATION
   â”œâ”€ Clean: Remove errors, handle missing values
   â”œâ”€ Transform: Convert to proper format
   â””â”€ Feature Engineering: Create new features
   
3. EXPLORATORY DATA ANALYSIS
   â”œâ”€ Visualize data
   â”œâ”€ Find patterns
   â””â”€ Check for correlations
   
4. MODEL SELECTION
   â”œâ”€ Choose algorithm (Linear, Tree, Neural Net, etc.)
   â”œâ”€ Set hyperparameters
   â””â”€ Consider computational needs
   
5. MODEL TRAINING
   â”œâ”€ Split into train/test (70/30 or 80/20)
   â”œâ”€ Train on training data
   â””â”€ Track training progress
   
6. MODEL EVALUATION
   â”œâ”€ Test on test data (NOT training data)
   â”œâ”€ Calculate metrics (accuracy, precision, recall)
   â””â”€ Check for overfitting
   
7. HYPERPARAMETER TUNING
   â”œâ”€ Adjust parameters
   â”œâ”€ Try different algorithms
   â””â”€ Compare results
   
8. DEPLOYMENT
   â”œâ”€ Save model
   â”œâ”€ Create API/service
   â””â”€ Monitor performance

Key terms:
- Features: Input variables (X)
- Labels: Output variables (y)
- Training set: Data used to train model
- Test set: Data used to evaluate model
- Overfitting: Model memorizes training data
- Underfitting: Model is too simple
""")


# ===== SECTION 5: Types of Machine Learning =====
print("\n=== TYPES OF MACHINE LEARNING ===\n")

print("""
1. SUPERVISED LEARNING
   â”œâ”€ Classification
   â”‚  â”œâ”€ Binary: Yes/No, Spam/Not Spam
   â”‚  â””â”€ Multi-class: Iris type, Hand-written digit
   â”‚
   â””â”€ Regression
      â””â”€ Predict numerical values: House price, Temperature

2. UNSUPERVISED LEARNING
   â”œâ”€ Clustering: Group similar items
   â”‚  â”œâ”€ K-Means
   â”‚  â””â”€ Hierarchical Clustering
   â”‚
   â””â”€ Dimensionality Reduction: Reduce features
      â””â”€ PCA: Principal Component Analysis

3. REINFORCEMENT LEARNING
   â””â”€ Agent learns through rewards/penalties
      â”œâ”€ Game AI
      â”œâ”€ Robot control
      â””â”€ Autonomous driving

4. DEEP LEARNING
   â””â”€ Neural networks with multiple layers
      â”œâ”€ Image recognition
      â”œâ”€ Natural language processing
      â””â”€ Time series forecasting

In this workshop: Focus on Supervised Learning (Classification)
""")


# ===== SECTION 6: Simple Prediction Example =====
print("\n=== SIMPLE PREDICTION EXAMPLE ===\n")

print("""
Use case: Predict if someone will buy a product

Features:
- Age
- Income
- Previous purchases
- Time spent on site

Label:
- Bought (Yes/No)

Steps:
1. Collect historical data
2. Train model with features and labels
3. Use trained model to predict for new customer
""")

try:
    import numpy as np
    from sklearn.preprocessing import StandardScaler
    from sklearn.tree import DecisionTreeClassifier
    
    # Simulated customer data
    # Features: [Age, Income (in $1000s), Previous Purchases]
    X = np.array([
        [25, 30, 2],   # Young, low income, few purchases -> No
        [45, 80, 15],  # Middle age, high income, many purchases -> Yes
        [30, 50, 5],   # Young, medium income, some purchases -> Yes
        [22, 25, 1],   # Young, low income, no purchases -> No
        [55, 100, 20], # Older, high income, many purchases -> Yes
        [35, 60, 10],  # Middle age, medium income, some purchases -> Yes
    ])
    
    # Labels: 0 = No purchase, 1 = Yes purchase
    y = np.array([0, 1, 1, 0, 1, 1])
    
    # Train model
    model = DecisionTreeClassifier(random_state=42)
    model.fit(X, y)
    
    # Predict for new customer
    new_customer = [[30, 55, 8]]  # 30 years old, $55k income, 8 previous purchases
    prediction = model.predict(new_customer)
    probability = model.predict_proba(new_customer)
    
    print("Customer Profile:")
    print(f"  Age: 30")
    print(f"  Income: $55,000")
    print(f"  Previous Purchases: 8")
    
    print(f"\nPrediction:")
    print(f"  Will buy: {'Yes' if prediction[0] == 1 else 'No'}")
    print(f"  Confidence (No): {probability[0][0]:.2%}")
    print(f"  Confidence (Yes): {probability[0][1]:.2%}")
    
except Exception as e:
    print(f"Error running example: {e}")


# ===== SECTION 7: AI/ML Roadmap =====
print("\n\n=== AI/ML LEARNING ROADMAP ===\n")

print("""
After this workshop, your learning path:

PHASE 1: FOUNDATIONS (Current + 2-4 weeks)
â”œâ”€ Python fundamentals âœ“
â”œâ”€ Data manipulation (Pandas)
â”œâ”€ Basic statistics
â””â”€ Visualization (Matplotlib, Seaborn)

PHASE 2: MACHINE LEARNING (4-8 weeks)
â”œâ”€ Supervised learning algorithms
â”œâ”€ Model evaluation and validation
â”œâ”€ Feature engineering
â”œâ”€ Classification problems
â””â”€ Regression problems

PHASE 3: ADVANCED TECHNIQUES (8-16 weeks)
â”œâ”€ Ensemble methods
â”œâ”€ Cross-validation
â”œâ”€ Hyperparameter tuning
â”œâ”€ Text processing (NLP)
â””â”€ Time series analysis

PHASE 4: DEEP LEARNING (16+ weeks)
â”œâ”€ Neural networks (TensorFlow/Keras)
â”œâ”€ Convolutional Neural Networks (CNN) - Image recognition
â”œâ”€ Recurrent Neural Networks (RNN) - Sequential data
â””â”€ Transformers - State-of-the-art NLP

PHASE 5: SPECIALIZATION (Choose your path)
â”œâ”€ Computer Vision
â”‚  â””â”€ Object detection, Image segmentation
â”œâ”€ Natural Language Processing (NLP)
â”‚  â””â”€ Text classification, Translation
â”œâ”€ Recommender Systems
â”‚  â””â”€ Personalized recommendations
â”œâ”€ Reinforcement Learning
â”‚  â””â”€ Game AI, Robotics
â””â”€ MLOps & Deployment
   â””â”€ Model serving, Monitoring, Scaling

Resources:
- Kaggle (datasets and competitions)
- Coursera (structured courses)
- Fast.ai (practical deep learning)
- Papers With Code (latest research)
""")


# ===== SECTION 8: AI in Real World =====
print("\n=== AI IN REAL WORLD ===\n")

print("""
Current AI Applications:

1. RECOMMENDATION SYSTEMS
   â”œâ”€ Netflix: Movie recommendations
   â”œâ”€ Amazon: Product recommendations
   â””â”€ Spotify: Music recommendations

2. NATURAL LANGUAGE PROCESSING
   â”œâ”€ Chatbots (ChatGPT, Gemini, etc.)
   â”œâ”€ Translation (Google Translate)
   â”œâ”€ Sentiment analysis
   â””â”€ Text classification

3. COMPUTER VISION
   â”œâ”€ Face recognition
   â”œâ”€ Object detection
   â”œâ”€ Medical imaging
   â””â”€ Autonomous vehicles

4. AUTOMATION
   â”œâ”€ RPA (Robotic Process Automation)
   â”œâ”€ Document processing
   â”œâ”€ Data entry
   â””â”€ Customer service

5. PREDICTIVE ANALYTICS
   â”œâ”€ Stock price prediction
   â”œâ”€ Weather forecasting
   â”œâ”€ Disease diagnosis
   â””â”€ Customer churn prediction

6. GENERATIVE AI
   â”œâ”€ Image generation (DALL-E, Midjourney)
   â”œâ”€ Text generation (ChatGPT, Claude)
   â”œâ”€ Code generation (GitHub Copilot)
   â””â”€ Video generation

Career opportunities:
- Machine Learning Engineer
- Data Scientist
- AI Researcher
- MLOps Engineer
- AI Product Manager
- AI Ethics Specialist
""")


# ===== SECTION 9: AI + Automation Combined =====
print("\n=== AI + AUTOMATION ===\n")

print("""
Combining AI with Automation:

1. INTELLIGENT RPA
   â”œâ”€ Use AI to understand documents
   â”œâ”€ Automate decision-making
   â””â”€ Learn from new patterns

2. PREDICTIVE MAINTENANCE
   â”œâ”€ Monitor equipment with sensors
   â”œâ”€ Use ML to predict failures
   â”œâ”€ Schedule maintenance proactively
   â””â”€ Reduce downtime

3. INTELLIGENT WORKFLOWS
   â”œâ”€ Auto-route documents
   â”œâ”€ Classification
   â”œâ”€ Priority assignment
   â””â”€ Alert escalation

4. CHATBOT + AUTOMATION
   â”œâ”€ AI chatbot understands user intent
   â”œâ”€ Triggers automated workflows
   â”œâ”€ Handles complex scenarios
   â””â”€ Routes to human when needed

Tools:
- n8n + Python: Automation + ML
- Make.com: Visual automation + integrations
- Zapier: No-code automation + webhooks
- Custom Python scripts: Full control

Example:
  Automated Email Processing:
  1. Email arrives
  2. AI extracts information
  3. Automation routes to correct department
  4. Workflow starts automatically
  5. Sends status to user
""")


# ===== SECTION 10: Project Ideas Using AI + Automation =====
print("\n=== PROJECT IDEAS ===\n")

print("""
Beginner Projects:
1. Iris Flower Classification
   - Classic ML dataset
   - Learn classification basics
   - Implement DecisionTree, RandomForest

2. Email Spam Detection
   - Text classification
   - Learn about NLP basics
   - Feature extraction

3. House Price Prediction
   - Regression problem
   - Real estate dataset
   - Model evaluation

Intermediate Projects:
1. Customer Churn Prediction
   - Business analytics
   - Feature engineering
   - Model comparison

2. Sentiment Analysis
   - NLP + classification
   - Twitter/Review data
   - Deploy as API

3. Credit Risk Assessment
   - Binary classification
   - Business impact
   - Interpretability focus

Advanced Projects:
1. Image Classification
   - Deep learning
   - Convolutional neural networks
   - Transfer learning

2. Time Series Forecasting
   - Stock prices or weather
   - RNNs or LSTMs
   - Performance monitoring

3. Recommendation System
   - Collaborative filtering
   - Content-based recommendations
   - A/B testing
""")


# ===== SECTION 11: Next Steps =====
print("\n=== NEXT STEPS ===\n")

print("""
After completing this workshop:

Week 1-2: PRACTICE & REINFORCE
â”œâ”€ Re-run all lessons
â”œâ”€ Complete all exercises
â”œâ”€ Build the final projects
â””â”€ Share your work

Week 3-4: EXPLORE & EXPERIMENT
â”œâ”€ Try Kaggle datasets
â”œâ”€ Modify examples
â”œâ”€ Combine Day 1-3 concepts
â””â”€ Start simple ML project

Month 2: DEEPEN KNOWLEDGE
â”œâ”€ Take structured ML course
â”œâ”€ Learn more about Pandas & NumPy
â”œâ”€ Build real project with real data
â””â”€ Learn data visualization

Resources:
- Online Communities:
  â””â”€ r/learnprogramming, r/MachineLearning, Stack Overflow
- Practice Platforms:
  â””â”€ LeetCode, HackerRank, Codewars
- Free Courses:
  â””â”€ Fast.ai, Coursera (audit option), YouTube tutorials
- Books:
  â””â”€ \"Python Crash Course\", \"Hands-On ML with TensorFlow\"

Remember:
- Practice consistently
- Build projects, don't just watch tutorials
- Join communities and ask questions
- Share your learnings
- Celebrate small wins
- Keep learning!
""")


print("\nâœ… Lesson 10 Complete!")
print("ğŸ‰ You've completed Day 3 - AI & Automation Systems!")
print("\nğŸ“ WORKSHOP COMPLETE!")
print("â•" * 50)
print("You now have:")
print("âœ“ Python fundamentals")
print("âœ“ Automation skills")
print("âœ“ File handling capabilities")
print("âœ“ API integration knowledge")
print("âœ“ Introduction to AI/ML")
print("âœ“ Error handling experience")
print("\nNext: Work on Final Projects!")
print("â•" * 50)
